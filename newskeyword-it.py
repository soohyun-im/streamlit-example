import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from retrying import retry
import os
import openai

st.set_page_config(
    page_title="ë‰´ìŠ¤ ì† ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Setting the API key
openai.api_key = os.environ.get("OPENAI_API_KEY")

def get_main_news_data(category):
    url = f'https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1={category}'
    response = requests.get(url)

    if response.status_code != 200:
        st.error(f"ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')

    data_list = []

    # Find URLs and headlines with class sh_text
    sh_text_elements = soup.select('.sh_text')
    if sh_text_elements:
        for i, element in enumerate(sh_text_elements, 1):
            link = element.find('a')
            if link and 'href' in link.attrs:
                news_url = link['href']
                headline = link.get_text(strip=True)
                data_list.append({'url': news_url, 'headline': headline})

    return data_list

def get_contents_from_urls(news_data):
    contents_list = []

    for data in news_data:
        url = data['url']
        headline = data['headline']

        # ê° ê¸°ì‚¬ html ê°€ì ¸ì˜¤ê¸°
        news = make_request(url)
        news_html = BeautifulSoup(news.text, "html.parser")

        # ê¸°ì‚¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (id="dic_area"ì¸ div íƒœê·¸ì˜ ë‚´ìš© ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°)
        dic_area = news_html.find(id="dic_area")
        if dic_area:
            # Remove unnecessary tags (script, a, span, etc.)
            for tag in dic_area(['script', 'a', 'span']):
                tag.decompose()

            # Extract text content
            content = dic_area.get_text(strip=True)
            contents_list.append({'headline': headline, 'content': content})
        else:
            st.warning(f"ê¸°ì‚¬ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URL: {url}")

    return contents_list

def ask_to_gpt35_turbo(user_input):
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", 
             "content": """
            ë‹¹ì‹ ì€ ì„¸ìƒì˜ ëª¨ë“  ê¸°ì—…ê³¼ ê¸°ìˆ  ë° í–‰ì‚¬ì •ë³´ì— ëŒ€í•´ ì•Œê³ ìˆëŠ” ITë°±ê³¼ì‚¬ì „ì…ë‹ˆë‹¤. ì „ë‹¬ëœ ITë‰´ìŠ¤ë¥¼ ë³´ê³  ê¸°ì‚¬ì—ë‚˜ì˜¨ ê¸°ì—…ëª…ê³¼ ê¸°ìˆ ëª… ê·¸ë¦¬ê³  í–‰ì‚¬ëª…ì„ ì°¾ì•„ì£¼ì„¸ìš”
            ê¸°ìˆ ì´ë€ ìœ  ë¬´í˜•ì˜ ê¸°ìˆ  ë° ì„œë¹„ìŠ¤ì™€ ì œí’ˆì„ í¬í•¨í•˜ëŠ” ê°œë…ì´ë©°, ë‰´ìŠ¤ì—ì„œ ì†Œê°œí•˜ê³ ìí•˜ëŠ” ì¤‘ì‹¬ë‚´ìš©ì…ë‹ˆë‹¤. 
            ì•„ë˜ì˜ ì œì•½ì¡°ê±´ê³¼ ì¶œë ¥í˜•ì‹ì—ë”°ë¼ ì…ë ¥ë¬¸ì— ëŒ€í•œ ë‹¨ì–´ëª©ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”  
            í•´ë‹¹ ë‹¨ì–´ëª©ë¡ì„ í†µí•´ ITê¸°ì‚¬ì— ë‚˜ì˜¨ ê¸°ì—…ê³¼ ê¸°ìˆ , í–‰ì‚¬ ëª©ë¡ì„ userì—ê²Œ ë¹ ë¥´ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤.
            Please output the keywords in the following format:\n- ê¸°ì—…: [Company Names](english name)\n- í–‰ì‚¬: [Event Names](english name)\n- ê¸°ìˆ : [Technology Names](english name)
            """},
            
            {"role": "user", "content": user_input},
            
            {"role": "assistant", 
             "content": """
              #ì œì•½ì¡°ê±´
              -ë‹¨ì–´ëŠ” ìµœì†Œí•œì˜ ëª…ì‚¬ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤
              -ë³‘ê¸°í•  ë‹¨ì–´ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ì œì™¸í•˜ê³  í•œê¸€ë¡œ ì í˜€ìˆëŠ” ê²½ìš° ì˜ë¬¸ëª…ì„ ë³‘ê¸°í•˜ê³ , ì˜ë¬¸ëª…ì¼ê²½ìš° í•œê¸€ëª…ì„ ë°˜ë“œì‹œ ë³‘ê¸°í•©ë‹ˆë‹¤.
              -ì¶”ì¶œ ì‹œ ê°ê° ë‹¨ì–´ë¥¼ ì¤‘ë³µ ì¶”ì¶œí•˜ì§€ì•ŠìŠµë‹ˆë‹¤.
              -ê¸°ì—…ëª…,ê¸°ìˆ ëª… ê·¸ë¦¬ê³  í–‰ì‚¬ëª…ì´ ì•„ë‹Œ ë‹¨ì–´ëŠ” ì¶œë ¥í•˜ì§€ì•ŠìŠµë‹ˆë‹¤. 
              -í•´ë‹¹í•˜ëŠ” ë‹¨ì–´ê°€ ì¡´ì¬í•˜ì§€ì•ŠëŠ”ê²½ìš° 'none'ì´ë¼ê³  í‘œì‹œí•©ë‹ˆë‹¤.
              -ì½”ë“œë¸”ë¡ì€ í¬í•¨í•˜ì§€ì•ŠìŠµë‹ˆë‹¤.
              
              
              #ì¶œë ¥ í˜•ì‹
              \n- ê¸°ì—…: [Company Names](english name)\n- í–‰ì‚¬: [Event Names](english name)\n- ê¸°ìˆ : [Technology Names](english name)

              #ì¶œë ¥ ì˜ˆì‹œ
                -ê¸°ì—… : CJì˜¨ìŠ¤íƒ€ì¼(CJ Onstyle), ì‚¼ì„±ì „ì(Samsung Electronics)
                -í–‰ì‚¬ : ê°¤ëŸ­ì‹œ ì–¸íŒ© 2024(Galaxy Unpacked 2024)
                -ê¸°ìˆ  : ê°¤ëŸ­ì‹œ S24 ì‹œë¦¬ì¦ˆ(Galaxy S24 series), ìƒì„±í˜• AI(Generative AI)
            

              #ë„ì¶œê³¼ì •
              1. ì§ˆë¬¸ì—ëŒ€í•œ ë‚´ìš©ì´ ì£¼ì–´ì§„ ê¸°ì‚¬ì—ìˆëŠ”ì§€ í™•ì¸í•œë‹¤
              2. ì •ë³´ì•ˆì— ë‚´ìš©ì´ ìˆëŠ”ê²½ìš° ì •í•´ì§„ ì¶œë ¥í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.
              3. ì •ë³´ì•ˆì— ë‚´ìš©ì´ ì—†ëŠ”ê²½ìš° ì—†ìŒ ì´ë¼ê³  ì¶œë ¥í•œë‹¤.
              4. ì¶œë ¥í˜•ì‹ ì´ì™¸ì˜ ë‹¨ì–´ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ì•ŠëŠ”ë‹¤.

            

             """}
        ]
    )

    return response.choices[0].message.content

@retry(stop_max_attempt_number=3, wait_fixed=1000)  # 3ë²ˆ ì¬ì‹œë„í•˜ë©° 1ì´ˆ ê°„ê²©ìœ¼ë¡œ
def make_request(url):
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    return response

def main():
    st.title("IT ë‰´ìŠ¤ ì† ê¸°ì—…/ê¸°ìˆ /í–‰ì‚¬ í‚¤ì›Œë“œ ì°¾ê¸° ğŸ”")
    category = 105
    if st.button("ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"):
        # ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        news_data = get_main_news_data(category)

        if news_data:
            st.subheader("í—¤ë“œë¼ì¸ ë‰´ìŠ¤")
            for i, data in enumerate(news_data, 1):
                # Determine text color based on background color
                background_color = st.session_state.background_color if "background_color" in st.session_state else "#FFFFFF"
                text_color = "#262730" if background_color == "#FFFFFF" else "#FFFFFF"

                # Adjust the style for dark mode
                div_style = f"padding: 5px; {'background-color: #F0F2F6;' if background_color != '#1E1E1E' else ''}"
                st.markdown(
                    f"<div style='color: {text_color}; {div_style}'>{i}.{data['headline']}</div>",
                    unsafe_allow_html=True,
                )
                st.write(f"   URL: {data['url']}")

                # ê¸°ì‚¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                contents = get_contents_from_urls([data])
                if contents:
                    st.write("ë‰´ìŠ¤ ë‚´ìš© ë¶„ì„ ì¤‘...")

                    # GPT-3.5 Turbo ëª¨ë¸ì— ê¸°ì‚¬ ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ
                    user_request = f"""
                    ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë³´ê³  ê¸°ì—…ëª…,ê¸°ìˆ ëª…,í–‰ì‚¬ëª…ì„ ì°¾ì•„ ì¶œë ¥í˜•ì‹ëŒ€ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”: 
                    {contents[0]['content']}
                    """
                    extracted_keywords = ask_to_gpt35_turbo(user_request)

                    # Store data in dictionary
                    data['Content'] = contents[0]['content']
                    data['Extracted Keywords'] = extracted_keywords

                    # Display data
                    #unique_keywords = list(set(extracted_keywords.split(',')))

                    st.markdown(f"<h4>ì¶”ì¶œ í‚¤ì›Œë“œ</h4>", unsafe_allow_html=True)
                    # Display extracted keywords with dynamic text color
                    keyword_bg_color = "#f0f8ff" if background_color != '#1E1E1E' else ''
                    st.markdown(
                        f"<div style='color: {text_color}; background-color: {keyword_bg_color}; padding: 10px;'>{extracted_keywords}</div>",
                        unsafe_allow_html=True,
                    )
                    
                    st.markdown("<br>", unsafe_allow_html=True)

                    st.markdown(f"<h6>ê¸°ì‚¬ ë‚´ìš© ì „ë¬¸ ë³´ê¸°</h6>", unsafe_allow_html=True)

                    # Adjust the style for dark mode in detailed content
                    content_style = f"font-size: 14px; color: {text_color}; {'background-color: #FFFFFF;' if background_color != '#1E1E1E' else ''}"
                    st.markdown(
                        f"<p style='{content_style}'>{contents[0]['content']}</p>",
                        unsafe_allow_html=True,
                    )

                else:
                    st.warning("ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ë° ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")


            # Convert dictionary to DataFrame
            df = pd.DataFrame(news_data)

            # Display the entire DataFrame
            st.subheader("ì „ì²´ ë°ì´í„° í”„ë ˆì„")
            st.write(df)


if __name__ == "__main__":
    main()
